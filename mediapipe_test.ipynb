{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "jab_color_files = [file for file in glob.glob('./numpy_data_arrays/jab/*color.npz')]\n",
    "cross_color_files = [file for file in glob.glob('./numpy_data_arrays/cross/*color.npz')]\n",
    "left_hook_color_files = [file for file in glob.glob('./numpy_data_arrays/left_hook/*color.npz')]\n",
    "right_hook_color_files = [file for file in glob.glob('./numpy_data_arrays/right_hook/*color.npz')]\n",
    "random_color_files = [file for file in glob.glob('./numpy_data_arrays/random/*color.npz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 6 frames evenly spread out\n",
    "def extract_frames(frames):\n",
    "    extracted_frames = []\n",
    "    for i in range(1, 7):\n",
    "        frame_to_extract = (i * (frames.shape[0]) // 6 ) - 1\n",
    "        extracted_frames.append(frames[frame_to_extract])\n",
    "    return np.array(extracted_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 383, 383, 4)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data = np.load(right_hook_color_files[5])\n",
    "color_data = load_data[\"arr_0\"]\n",
    "frames = extract_frames(color_data)\n",
    "\n",
    "\n",
    "for i, frame in enumerate(frames):\n",
    "    cv2.imshow(f'Frame {i}', frame)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(frames):\n",
    "    landmarks_coords = []\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        for frame in frames:\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            pose_results = pose.process(image)\n",
    "\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            try:\n",
    "                landmarks = pose_results.pose_landmarks.landmark\n",
    "                # print (landmarks)\n",
    "                landmarks_coords.append([[landmark.x, landmark.y] for landmark in landmarks])\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "        return np.array(landmarks_coords).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for file in jab_color_files:\n",
    "    load_data = np.load(file)\n",
    "    color_data = load_data['arr_0']\n",
    "    frames = extract_frames(color_data)\n",
    "    landmarks = get_landmarks(frames)\n",
    "    X.append(landmarks)\n",
    "    y.append('jab')\n",
    "\n",
    "for file in cross_color_files:\n",
    "    load_data = np.load(file)\n",
    "    color_data = load_data['arr_0']\n",
    "    frames = extract_frames(color_data)\n",
    "    landmarks = get_landmarks(frames)\n",
    "    X.append(landmarks)\n",
    "    y.append('cross')\n",
    "\n",
    "for file in left_hook_color_files:\n",
    "    load_data = np.load(file)\n",
    "    color_data = load_data['arr_0']\n",
    "    frames = extract_frames(color_data)\n",
    "    landmarks = get_landmarks(frames)\n",
    "    X.append(landmarks)\n",
    "    y.append('left_hook')\n",
    "\n",
    "for file in right_hook_color_files:\n",
    "    load_data = np.load(file)\n",
    "    color_data = load_data['arr_0']\n",
    "    frames = extract_frames(color_data)\n",
    "    landmarks = get_landmarks(frames)\n",
    "    X.append(landmarks)\n",
    "    y.append('right_hook')\n",
    "\n",
    "for file in random_color_files:\n",
    "    load_data = np.load(file)\n",
    "    color_data = load_data['arr_0']\n",
    "    frames = extract_frames(color_data)\n",
    "    landmarks = get_landmarks(frames)\n",
    "    X.append(landmarks)\n",
    "    y.append('random')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(y)\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def run_kfolds(model, x, y, splits):\n",
    "    kf = KFold(n_splits=splits, shuffle=True)\n",
    "    scores = cross_val_score(model, x, y, cv=kf, scoring=\"accuracy\")\n",
    "    predict = cross_val_predict(model, x, y, cv=kf)\n",
    "    return scores, predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "SVM = SVC(kernel='linear')\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Get the class labels from LabelEncoder\n",
    "# class_labels = label_encoder.classes_\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(3,3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='linear')\n",
    "\n",
    "scores, predicts = run_kfolds(SVM, X, y, 5)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y, predicts)\n",
    "svm_report = classification_report(y, predicts)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"SVM Cross-Validation Classification Report:\")\n",
    "print(svm_report)\n",
    "\n",
    "cm = confusion_matrix(y, predicts)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data = np.load(jab_color_files[1])\n",
    "# color_data = load_data['arr_0']\n",
    "\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     for frame in color_data:\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)\n",
    "#         image.flags.writeable = False\n",
    "#         cv2.imshow(\"IMAGE DETECTIONS\", image)\n",
    "\n",
    "#         pose_results = pose.process(image)\n",
    "\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         mp_drawing.draw_landmarks(image, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                   mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "#                                   mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "#                                   )\n",
    "#         cv2.imshow(\"MEDIAPIPE DETECTIONS\", image)\n",
    "        \n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     for frame in color_data:\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)\n",
    "#         image.flags.writeable = False\n",
    "\n",
    "#         pose_results = pose.process(image)\n",
    "\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         try:\n",
    "#             landmarks = pose_results.pose_landmarks.landmark\n",
    "#             print (landmarks)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         mp_drawing.draw_landmarks(image, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                   mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "#                                   mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "#                                   )\n",
    "#         cv2.imshow(\"MEDIAPIPE DETECTIONS\", image)\n",
    "        \n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for landmark in mp_pose.PoseLandmark:\n",
    "#     print((landmark))\n",
    "\n",
    "[(e, e.value) for e in mp_pose.PoseLandmark]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterations vs Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB = GaussianNB()\n",
    "\n",
    "scores, predicts = run_kfolds(NB, X, y, 5)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y, predicts)\n",
    "nb_report = classification_report(y, predicts)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"NB Cross-Validation Classification Report:\")\n",
    "print(nb_report)\n",
    "\n",
    "cm = confusion_matrix(y, predicts)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "scores, predicts = run_kfolds(rf, X, y, 5)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y, predicts)\n",
    "rf_report = classification_report(y, predicts)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Random Forest Cross-Validation Classification Report:\")\n",
    "print(rf_report)\n",
    "\n",
    "cm = confusion_matrix(y, predicts)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# mlp_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Display the evaluation metrics\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"mlp Classification Report:\")\n",
    "# print(mlp_report)\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# # Get the class labels from LabelEncoder\n",
    "# # class_labels = label_encoder.classes_\n",
    "\n",
    "# # Display the confusion matrix as a heatmap\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# initialize the classifier\n",
    "#MLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "MLP = MLPClassifier(max_iter=150)\n",
    "\n",
    "MLP.fit(X_train, y_train)\n",
    "y_pred = MLP.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mlp_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"mlp Classification Report:\")\n",
    "print(mlp_report)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Get the class labels from LabelEncoder\n",
    "# class_labels = label_encoder.classes_\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# initialize the classifier\n",
    "#MLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "MLP = MLPClassifier(max_iter=800)\n",
    "scores, predicts = run_kfolds(MLP, X, y, 5)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y, predicts)\n",
    "mlp_report = classification_report(y, predicts)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"MLP Cross-Validation Classification Report:\")\n",
    "print(mlp_report)\n",
    "\n",
    "cm = confusion_matrix(y, predicts)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
